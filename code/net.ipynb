{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "painful-function",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import SparkSession\n",
    "import findspark\n",
    "findspark.init()\n",
    "\n",
    "from pyspark.ml.evaluation import MulticlassClassificationEvaluator\n",
    "from pyspark.ml.classification import MultilayerPerceptronClassifier\n",
    "from pyspark.sql import SparkSession\n",
    "import random\n",
    "import sys\n",
    "#path = str(sys.argv[1])\n",
    "#atr = int(sys.argv[2])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "later-track",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Build the SparkSession\n",
    "spark = SparkSession.builder \\\n",
    "    .master(\"local[6]\") \\\n",
    "    .appName(\"Data exploration URL\") \\\n",
    "    .config(\"spark.executor.memory\", \"6gb\") \\\n",
    "    .getOrCreate()\n",
    "\n",
    "sc = spark.sparkContext"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "brazilian-fellowship",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('spark.driver.memory', '6g'),\n",
       " ('spark.rdd.compress', 'True'),\n",
       " ('spark.app.id', 'local-1614630030387'),\n",
       " ('spark.driver.port', '41281'),\n",
       " ('spark.serializer.objectStreamReset', '100'),\n",
       " ('spark.submit.pyFiles', ''),\n",
       " ('spark.executor.id', 'driver'),\n",
       " ('spark.executor.memory', '6gb'),\n",
       " ('spark.app.name', 'Data exploration URL'),\n",
       " ('spark.submit.deployMode', 'client'),\n",
       " ('spark.ui.showConsoleProgress', 'true'),\n",
       " ('spark.master', 'local[6]'),\n",
       " ('spark.driver.host', 'fedora')]"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sc._conf.getAll()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "smaller-annual",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load training data\n",
    "data = spark.read.format(\"libsvm\")\\\n",
    "    .load(\"../data/url_svmlight/instances_5k.svm\")\n",
    "# Split the data into train and test\n",
    "seed = random.randrange(500, 1300, 2)\n",
    "splits = data.randomSplit([0.6, 0.4], seed)\n",
    "\n",
    "train = splits[0]\n",
    "test = splits[1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "domestic-medicine",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[Row(label=0.0, features=SparseVector(3231949, {3: 0.0788, 4: 0.1241, 5: 0.1176, 10: 0.4286, 15: 0.1, 16: 0.7496, 17: 0.843, 18: 0.1973, 20: 0.1429, 21: 0.1429, 22: 0.1429, 27: 1.0, 32: 0.0556, 40: 0.1, 53: 1.0, 55: 1.0, 63: 1.0, 69: 1.0, 71: 1.0, 73: 1.0, 75: 1.0, 81: 1.0, 83: 1.0, 85: 1.0, 87: 1.0, 89: 1.0, 91: 1.0, 93: 1.0, 95: 1.0, 101: 1.0, 103: 1.0, 105: 1.0, 107: 1.0, 109: 1.0, 111: 1.0, 154: 1.0, 189: 1.0, 203: 1.0, 358: 1.0, 359: 1.0, 360: 1.0, 1305: 1.0, 1308: 1.0, 1309: 1.0, 1310: 1.0, 2407: 1.0, 2920: 1.0, 2922: 1.0, 6999: 1.0, 7000: 1.0, 7001: 1.0, 7004: 1.0, 7005: 1.0, 7006: 1.0, 7008: 1.0, 7009: 1.0, 7758: 1.0, 7761: 1.0, 155152: 1.0, 155153: 1.0, 155154: 1.0, 155155: 1.0, 155156: 1.0, 155157: 1.0, 155158: 1.0, 155159: 1.0, 155160: 1.0, 155162: 1.0, 155163: 1.0, 155164: 1.0, 155165: 1.0, 155167: 1.0, 155168: 1.0, 155169: 1.0, 155171: 1.0, 155172: 1.0, 155173: 1.0, 155174: 1.0, 155175: 1.0, 155176: 1.0, 155177: 1.0, 155178: 1.0, 155179: 1.0, 155180: 1.0, 155181: 1.0, 155182: 1.0, 155193: 1.0, 155194: 1.0, 155195: 1.0, 155196: 1.0, 155197: 1.0, 155198: 1.0, 155199: 1.0, 155200: 1.0, 155201: 1.0, 155202: 1.0, 155203: 1.0, 155204: 1.0, 155205: 1.0, 155206: 1.0, 155207: 1.0, 155208: 1.0, 155209: 1.0, 155210: 1.0, 155211: 1.0, 155212: 1.0, 945788: 1.0, 1988570: 1.0, 2139256: 1.0, 2987738: 1.0, 3224680: 1.0}))]"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.take(1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "departmental-premiere",
   "metadata": {},
   "outputs": [],
   "source": [
    "# specify layers for the neural network:\n",
    "# input layer of size 4 (features), two intermediate of size 5 and 4\n",
    "# and output of size 3 (classes)\n",
    "layers = [3231949, 5, 4, 2]\n",
    "\n",
    "# create the trainer and set its parameters\n",
    "trainer = MultilayerPerceptronClassifier(\n",
    "    maxIter=100, layers=layers, blockSize=100000, seed=1234)\n",
    "\n",
    "# train the model\n",
    "model = trainer.fit(train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "ultimate-spoke",
   "metadata": {},
   "outputs": [],
   "source": [
    "# compute accuracy on the test set\n",
    "result = model.transform(test)\n",
    "predictionAndLabels = result.select(\"prediction\", \"label\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "lined-royalty",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "f1: 0.9828362262979538\n",
      "weightedPrecision: 0.9838362068965518\n",
      "weightedRecall: 0.9827586206896552\n",
      "Accuracy: 0.9827586206896551\n"
     ]
    }
   ],
   "source": [
    "evaluator = MulticlassClassificationEvaluator(metricName=\"f1\")\n",
    "print(\"f1: \" + str(evaluator.evaluate(predictionAndLabels)))\n",
    "evaluator = MulticlassClassificationEvaluator(metricName=\"weightedPrecision\")\n",
    "print(\"weightedPrecision: \" + str(evaluator.evaluate(predictionAndLabels)))\n",
    "evaluator = MulticlassClassificationEvaluator(metricName=\"weightedRecall\")\n",
    "print(\"weightedRecall: \" + str(evaluator.evaluate(predictionAndLabels)))\n",
    "evaluator = MulticlassClassificationEvaluator(metricName=\"accuracy\")\n",
    "print(\"Accuracy: \" + str(evaluator.evaluate(predictionAndLabels)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "covered-holiday",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "current-vocabulary",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "operating-romania",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "tight-cocktail",
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyspark import SparkConf, SparkContext\n",
    "from pyspark.sql.types import StringType\n",
    "from pyspark import SQLContext\n",
    "from pyspark.sql import functions as F\n",
    "conf = SparkConf().setMaster(\"local[11]\").setAppName(\"KDD\")\n",
    "conf.set(\"spark.driver.memory\", \"28g\") \n",
    "sc=SparkContext(conf=conf)\n",
    "sqlContext=SQLContext(sc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "plastic-firmware",
   "metadata": {},
   "outputs": [],
   "source": [
    "dfspark=sqlContext.read.format(\"csv\").option(\"header\",\"true\").option(\"inferSchema\",\"true\").load('../data/url_svmlight/prueba.svm')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "operating-uganda",
   "metadata": {},
   "outputs": [],
   "source": [
    "dfspark.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "french-hypothesis",
   "metadata": {},
   "outputs": [],
   "source": [
    "dfspark.printSchema()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.8.5 64-bit ('base': conda)",
   "language": "python",
   "name": "python38564bitbaseconda596aabc4316c46b392e16f5639a7998d"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
