{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "passive-language",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import SparkSession\n",
    "import findspark\n",
    "findspark.init()\n",
    "\n",
    "from pyspark.ml.evaluation import MulticlassClassificationEvaluator\n",
    "from pyspark.ml.classification import MultilayerPerceptronClassifier\n",
    "from pyspark.sql import SparkSession\n",
    "import random\n",
    "import sys\n",
    "#path = str(sys.argv[1])\n",
    "#atr = int(sys.argv[2])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "unique-rates",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Build the SparkSession\n",
    "spark = SparkSession.builder \\\n",
    "    .master(\"local[6]\") \\\n",
    "    .appName(\"Data exploration URL\") \\\n",
    "    .config(\"spark.executor.memory\", \"6gb\") \\\n",
    "    .getOrCreate()\n",
    "\n",
    "sc = spark.sparkContext"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "color-business",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('spark.driver.memory', '6g'),\n",
       " ('spark.rdd.compress', 'True'),\n",
       " ('spark.driver.port', '44733'),\n",
       " ('spark.serializer.objectStreamReset', '100'),\n",
       " ('spark.submit.pyFiles', ''),\n",
       " ('spark.executor.id', 'driver'),\n",
       " ('spark.executor.memory', '6gb'),\n",
       " ('spark.app.name', 'Data exploration URL'),\n",
       " ('spark.submit.deployMode', 'client'),\n",
       " ('spark.app.id', 'local-1614703368308'),\n",
       " ('spark.master', 'local[6]'),\n",
       " ('spark.ui.showConsoleProgress', 'true'),\n",
       " ('spark.driver.host', 'fedora')]"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sc._conf.getAll()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "killing-collaboration",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load training data\n",
    "data = spark.read.format(\"libsvm\")\\\n",
    "    .load(\"../data/url_svmlight/prueba_10.svm\")\n",
    "# Split the data into train and test\n",
    "seed = random.randrange(500, 1300, 2)\n",
    "splits = data.randomSplit([0.6, 0.4], seed)\n",
    "\n",
    "train = splits[0]\n",
    "test = splits[1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "intelligent-rugby",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[Row(label=0.0, features=SparseVector(3209930, {3: 0.0581, 4: 0.0897, 5: 0.1765, 10: 0.1429, 20: 0.2857, 21: 0.0238, 23: 1.0, 24: 1.0, 27: 1.0, 35: 1.0, 43: 1.0, 53: 1.0, 55: 1.0, 61: 1.0, 63: 1.0, 65: 1.0, 67: 1.0, 69: 1.0, 71: 1.0, 73: 1.0, 75: 1.0, 81: 1.0, 83: 1.0, 85: 1.0, 87: 1.0, 89: 1.0, 91: 1.0, 93: 1.0, 95: 1.0, 101: 1.0, 103: 1.0, 105: 1.0, 107: 1.0, 109: 1.0, 111: 1.0, 128: 1.0, 150: 1.0, 152: 1.0, 154: 1.0, 711: 1.0, 712: 1.0, 713: 1.0, 714: 1.0, 715: 1.0, 716: 1.0, 1281: 1.0, 1282: 1.0, 1283: 1.0, 1284: 1.0, 1285: 1.0, 1286: 1.0, 3482: 1.0, 4121: 1.0, 8156: 1.0, 155152: 1.0, 155153: 1.0, 155154: 1.0, 155155: 1.0, 155156: 1.0, 155162: 1.0, 155163: 1.0, 155165: 1.0, 155167: 1.0, 155168: 1.0, 155169: 1.0, 155171: 1.0, 155172: 1.0, 155173: 1.0, 155174: 1.0, 155175: 1.0, 155176: 1.0, 155177: 1.0, 155178: 1.0, 155179: 1.0, 155180: 1.0, 155181: 1.0, 155182: 1.0, 155193: 1.0, 155194: 1.0, 155195: 1.0, 155196: 1.0, 155197: 1.0, 155198: 1.0, 155199: 1.0, 155200: 1.0, 155201: 1.0, 155202: 1.0, 155203: 1.0, 155204: 1.0, 155205: 1.0, 155206: 1.0, 155207: 1.0, 155208: 1.0, 155209: 1.0, 155210: 1.0, 155211: 1.0, 155212: 1.0, 929753: 1.0}))]"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.take(1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "random-services",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "ERROR:root:Internal Python error in the inspect module.\n",
      "Below is the traceback from this internal error.\n",
      "\n",
      "Exception ignored in: <function JavaObject.__init__.<locals>.<lambda> at 0x7fc9ccca61f0>\n",
      "Traceback (most recent call last):\n",
      "  File \"/opt/spark/python/lib/py4j-0.10.9-src.zip/py4j/java_gateway.py\", line 1341, in <lambda>\n",
      "KeyboardInterrupt: \n",
      "Exception ignored in: <function JavaObject.__init__.<locals>.<lambda> at 0x7fc9ccb97670>\n",
      "Traceback (most recent call last):\n",
      "  File \"/opt/spark/python/lib/py4j-0.10.9-src.zip/py4j/java_gateway.py\", line 1341, in <lambda>\n",
      "  File \"/opt/spark/python/lib/py4j-0.10.9-src.zip/py4j/java_gateway.py\", line 645, in _garbage_collect_object\n",
      "  File \"/opt/spark/python/lib/py4j-0.10.9-src.zip/py4j/java_gateway.py\", line 964, in garbage_collect_object\n",
      "  File \"/opt/spark/python/lib/py4j-0.10.9-src.zip/py4j/java_gateway.py\", line 1031, in send_command\n",
      "  File \"/opt/spark/python/lib/py4j-0.10.9-src.zip/py4j/java_gateway.py\", line 979, in _get_connection\n",
      "  File \"/opt/spark/python/lib/py4j-0.10.9-src.zip/py4j/java_gateway.py\", line 985, in _create_connection\n",
      "  File \"/opt/spark/python/lib/py4j-0.10.9-src.zip/py4j/java_gateway.py\", line 1119, in start\n",
      "  File \"/opt/spark/python/lib/py4j-0.10.9-src.zip/py4j/java_gateway.py\", line 1135, in _authenticate_connection\n",
      "  File \"/opt/spark/python/lib/py4j-0.10.9-src.zip/py4j/java_gateway.py\", line 1200, in send_command\n",
      "  File \"/home/jsarabia/miniconda3/lib/python3.8/socket.py\", line 669, in readinto\n",
      "    return self._sock.recv_into(b)\n",
      "KeyboardInterrupt: \n",
      "Exception ignored in: <function JavaObject.__init__.<locals>.<lambda> at 0x7fc9ccb97e50>\n",
      "Traceback (most recent call last):\n",
      "  File \"/opt/spark/python/lib/py4j-0.10.9-src.zip/py4j/java_gateway.py\", line 1341, in <lambda>\n",
      "  File \"/opt/spark/python/lib/py4j-0.10.9-src.zip/py4j/java_gateway.py\", line 645, in _garbage_collect_object\n",
      "KeyboardInterrupt: \n",
      "Exception ignored in sys.unraisablehook: <built-in function unraisablehook>\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/jsarabia/miniconda3/lib/python3.8/site-packages/ipykernel/iostream.py\", line 350, in flush\n",
      "  File \"/home/jsarabia/miniconda3/lib/python3.8/threading.py\", line 558, in wait\n",
      "    signaled = self._cond.wait(timeout)\n",
      "  File \"/home/jsarabia/miniconda3/lib/python3.8/threading.py\", line 306, in wait\n",
      "    gotit = waiter.acquire(True, timeout)\n",
      "KeyboardInterrupt: \n",
      "Exception ignored in: <function JavaObject.__init__.<locals>.<lambda> at 0x7fc9ccca6040>\n",
      "Traceback (most recent call last):\n",
      "  File \"/opt/spark/python/lib/py4j-0.10.9-src.zip/py4j/java_gateway.py\", line 1341, in <lambda>\n",
      "  File \"/opt/spark/python/lib/py4j-0.10.9-src.zip/py4j/java_gateway.py\", line 645, in _garbage_collect_object\n",
      "KeyboardInterrupt: \n",
      "Exception ignored in: <function JavaObject.__init__.<locals>.<lambda> at 0x7fc9cc2c7a60>\n",
      "Traceback (most recent call last):\n",
      "  File \"/opt/spark/python/lib/py4j-0.10.9-src.zip/py4j/java_gateway.py\", line 1341, in <lambda>\n",
      "KeyboardInterrupt: \n",
      "Exception ignored in: <function JavaObject.__init__.<locals>.<lambda> at 0x7fc9cc2c79d0>\n",
      "Traceback (most recent call last):\n",
      "  File \"/opt/spark/python/lib/py4j-0.10.9-src.zip/py4j/java_gateway.py\", line 1341, in <lambda>\n",
      "  File \"/opt/spark/python/lib/py4j-0.10.9-src.zip/py4j/java_gateway.py\", line 645, in _garbage_collect_object\n",
      "  File \"/opt/spark/python/lib/py4j-0.10.9-src.zip/py4j/java_gateway.py\", line 964, in garbage_collect_object\n",
      "  File \"/opt/spark/python/lib/py4j-0.10.9-src.zip/py4j/java_gateway.py\", line 1031, in send_command\n",
      "  File \"/opt/spark/python/lib/py4j-0.10.9-src.zip/py4j/java_gateway.py\", line 979, in _get_connection\n",
      "  File \"/opt/spark/python/lib/py4j-0.10.9-src.zip/py4j/java_gateway.py\", line 985, in _create_connection\n",
      "  File \"/opt/spark/python/lib/py4j-0.10.9-src.zip/py4j/java_gateway.py\", line 1119, in start\n",
      "  File \"/opt/spark/python/lib/py4j-0.10.9-src.zip/py4j/java_gateway.py\", line 1135, in _authenticate_connection\n",
      "  File \"/opt/spark/python/lib/py4j-0.10.9-src.zip/py4j/java_gateway.py\", line 1200, in send_command\n",
      "  File \"/home/jsarabia/miniconda3/lib/python3.8/socket.py\", line 669, in readinto\n",
      "    return self._sock.recv_into(b)\n",
      "KeyboardInterrupt: \n",
      "Exception ignored in: <function JavaObject.__init__.<locals>.<lambda> at 0x7fc9cc2c7c10>\n",
      "Traceback (most recent call last):\n",
      "  File \"/opt/spark/python/lib/py4j-0.10.9-src.zip/py4j/java_gateway.py\", line 1341, in <lambda>\n",
      "  File \"/opt/spark/python/lib/py4j-0.10.9-src.zip/py4j/java_gateway.py\", line 645, in _garbage_collect_object\n",
      "  File \"/opt/spark/python/lib/py4j-0.10.9-src.zip/py4j/java_gateway.py\", line 964, in garbage_collect_object\n",
      "  File \"/opt/spark/python/lib/py4j-0.10.9-src.zip/py4j/java_gateway.py\", line 1031, in send_command\n",
      "  File \"/opt/spark/python/lib/py4j-0.10.9-src.zip/py4j/java_gateway.py\", line 979, in _get_connection\n",
      "  File \"/opt/spark/python/lib/py4j-0.10.9-src.zip/py4j/java_gateway.py\", line 985, in _create_connection\n",
      "  File \"/opt/spark/python/lib/py4j-0.10.9-src.zip/py4j/java_gateway.py\", line 1119, in start\n",
      "  File \"/opt/spark/python/lib/py4j-0.10.9-src.zip/py4j/java_gateway.py\", line 1135, in _authenticate_connection\n",
      "  File \"/opt/spark/python/lib/py4j-0.10.9-src.zip/py4j/java_gateway.py\", line 1200, in send_command\n",
      "  File \"/home/jsarabia/miniconda3/lib/python3.8/socket.py\", line 669, in readinto\n",
      "    return self._sock.recv_into(b)\n",
      "KeyboardInterrupt: \n",
      "Exception ignored in: <function JavaObject.__init__.<locals>.<lambda> at 0x7fc9cc2c7ca0>\n",
      "Traceback (most recent call last):\n",
      "  File \"/opt/spark/python/lib/py4j-0.10.9-src.zip/py4j/java_gateway.py\", line 1341, in <lambda>\n",
      "  File \"/opt/spark/python/lib/py4j-0.10.9-src.zip/py4j/java_gateway.py\", line 645, in _garbage_collect_object\n",
      "  File \"/opt/spark/python/lib/py4j-0.10.9-src.zip/py4j/java_gateway.py\", line 964, in garbage_collect_object\n",
      "  File \"/opt/spark/python/lib/py4j-0.10.9-src.zip/py4j/java_gateway.py\", line 1031, in send_command\n",
      "  File \"/opt/spark/python/lib/py4j-0.10.9-src.zip/py4j/java_gateway.py\", line 979, in _get_connection\n",
      "  File \"/opt/spark/python/lib/py4j-0.10.9-src.zip/py4j/java_gateway.py\", line 985, in _create_connection\n",
      "  File \"/opt/spark/python/lib/py4j-0.10.9-src.zip/py4j/java_gateway.py\", line 1119, in start\n",
      "  File \"/opt/spark/python/lib/py4j-0.10.9-src.zip/py4j/java_gateway.py\", line 1135, in _authenticate_connection\n",
      "  File \"/opt/spark/python/lib/py4j-0.10.9-src.zip/py4j/java_gateway.py\", line 1200, in send_command\n",
      "  File \"/home/jsarabia/miniconda3/lib/python3.8/socket.py\", line 669, in readinto\n",
      "    return self._sock.recv_into(b)\n",
      "KeyboardInterrupt: \n"
     ]
    }
   ],
   "source": [
    "# specify layers for the neural network:\n",
    "# input layer of size 4 (features), two intermediate of size 5 and 4\n",
    "# and output of size 3 (classes)\n",
    "layers = [3209930, 5, 4, 2]\n",
    "\n",
    "# create the trainer and set its parameters\n",
    "trainer = MultilayerPerceptronClassifier(\n",
    "    maxIter=100, layers=layers, blockSize=10000, seed=1234)\n",
    "\n",
    "# train the model\n",
    "model = trainer.fit(train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "aboriginal-chocolate",
   "metadata": {},
   "outputs": [],
   "source": [
    "# compute accuracy on the test set\n",
    "result = model.transform(test)\n",
    "predictionAndLabels = result.select(\"prediction\", \"label\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "introductory-bangladesh",
   "metadata": {},
   "outputs": [],
   "source": [
    "evaluator = MulticlassClassificationEvaluator(metricName=\"f1\")\n",
    "print(\"f1: \" + str(evaluator.evaluate(predictionAndLabels)))\n",
    "evaluator = MulticlassClassificationEvaluator(metricName=\"weightedPrecision\")\n",
    "print(\"weightedPrecision: \" + str(evaluator.evaluate(predictionAndLabels)))\n",
    "evaluator = MulticlassClassificationEvaluator(metricName=\"weightedRecall\")\n",
    "print(\"weightedRecall: \" + str(evaluator.evaluate(predictionAndLabels)))\n",
    "evaluator = MulticlassClassificationEvaluator(metricName=\"accuracy\")\n",
    "print(\"Accuracy: \" + str(evaluator.evaluate(predictionAndLabels)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "explicit-athletics",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "severe-binding",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "quantitative-climb",
   "metadata": {},
   "outputs": [],
   "source": [
    "x = 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "imperial-hammer",
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyspark import SparkConf, SparkContext\n",
    "from pyspark.sql.types import StringType\n",
    "from pyspark import SQLContext\n",
    "from pyspark.sql import functions as F\n",
    "conf = SparkConf().setMaster(\"local[11]\").setAppName(\"KDD\")\n",
    "conf.set(\"spark.driver.memory\", \"28g\") \n",
    "sc=SparkContext(conf=conf)\n",
    "sqlContext=SQLContext(sc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "cooperative-mobile",
   "metadata": {},
   "outputs": [],
   "source": [
    "dfspark=sqlContext.read.format(\"csv\").option(\"header\",\"true\").option(\"inferSchema\",\"true\").load('../data/url_svmlight/prueba.svm')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "thrown-catalog",
   "metadata": {},
   "outputs": [],
   "source": [
    "dfspark.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "framed-authority",
   "metadata": {},
   "outputs": [],
   "source": [
    "dfspark.printSchema()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.8.5 64-bit ('base': conda)",
   "language": "python",
   "name": "python38564bitbaseconda596aabc4316c46b392e16f5639a7998d"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
